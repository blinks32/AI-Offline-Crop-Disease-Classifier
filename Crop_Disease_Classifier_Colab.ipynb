{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå± Crop Disease Classification Model for Android\n",
    "\n",
    "This notebook creates a TensorFlow Lite model optimized for your Android crop disease detection app.\n",
    "\n",
    "## üìã What this notebook does:\n",
    "1. Creates a MobileNetV2-based model (optimized for mobile)\n",
    "2. Trains on crop disease dataset\n",
    "3. Converts to TensorFlow Lite with quantization\n",
    "4. Tests the model\n",
    "5. Provides download link for Android integration\n",
    "\n",
    "## üöÄ Quick Start:\n",
    "1. Upload your dataset or use a public one\n",
    "2. Run all cells\n",
    "3. Download the generated .tflite file\n",
    "4. Replace model.tflite in your Android project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install tensorflow matplotlib pillow\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "print(\"‚úÖ TensorFlow version:\", tf.__version__)\n",
    "print(\"‚úÖ GPU available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Modify these as needed\n",
    "CONFIG = {\n",
    "    'IMAGE_SIZE': (128, 128),  # Match your Android app (128x128 for current model)\n",
    "    'BATCH_SIZE': 32,\n",
    "    'EPOCHS': 15,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'NUM_CLASSES': 2,  # healthy, diseased\n",
    "    'MODEL_NAME': 'crop_disease_classifier_v2'\n",
    "}\n",
    "\n",
    "print(\"üìã Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Dataset Setup\n",
    "\n",
    "### Option 1: Use Kaggle Dataset (Recommended)\n",
    "Popular crop disease datasets on Kaggle:\n",
    "- [Plant Disease Dataset](https://www.kaggle.com/vipoooool/new-plant-diseases-dataset)\n",
    "- [Crop Disease Dataset](https://www.kaggle.com/rashikrahmanpritom/plant-disease-recognition-dataset)\n",
    "- [PlantVillage Dataset](https://www.kaggle.com/emmarex/plantdisease)\n",
    "\n",
    "### Option 2: Upload Your Own Dataset\n",
    "Structure your data like this:\n",
    "```\n",
    "dataset/\n",
    "  train/\n",
    "    healthy/\n",
    "      img1.jpg\n",
    "      img2.jpg\n",
    "    diseased/\n",
    "      img1.jpg\n",
    "      img2.jpg\n",
    "  val/\n",
    "    healthy/\n",
    "    diseased/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload PlantVillage dataset (RECOMMENDED)\n",
    "print(\"üìÅ Upload your PlantVillage dataset:\")\n",
    "uploaded = files.upload()  # Upload your plantvillage.zip file\n",
    "\n",
    "# Extract the dataset\n",
    "import zipfile\n",
    "zip_filename = list(uploaded.keys())[0]  # Get uploaded filename\n",
    "print(f\"Extracting {zip_filename}...\")\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "\n",
    "# Find the extracted folder\n",
    "import os\n",
    "folders = [f for f in os.listdir('.') if os.path.isdir(f) and ('plant' in f.lower() or 'village' in f.lower())]\n",
    "if not folders:\n",
    "    # Look for any folder with many subdirectories (likely the dataset)\n",
    "    folders = [f for f in os.listdir('.') if os.path.isdir(f) and len([d for d in os.listdir(f) if os.path.isdir(os.path.join(f, d))]) > 10]\n",
    "\n",
    "print(f\"Found dataset folders: {folders}\")\n",
    "dataset_folder = folders[0] if folders else None\n",
    "\n",
    "if dataset_folder:\n",
    "    print(f\"‚úÖ Using dataset folder: {dataset_folder}\")\n",
    "    \n",
    "    # Reorganize PlantVillage for binary classification\n",
    "    def setup_plantvillage_binary(dataset_path):\n",
    "        from pathlib import Path\n",
    "        import shutil\n",
    "        \n",
    "        print(\"üîÑ Reorganizing PlantVillage for binary classification...\")\n",
    "        \n",
    "        # Create output directories\n",
    "        output_dir = Path(\"crop_disease_dataset\")\n",
    "        train_dir = output_dir / \"train\"\n",
    "        val_dir = output_dir / \"val\"\n",
    "        \n",
    "        for split in [\"train\", \"val\"]:\n",
    "            for class_name in [\"healthy\", \"diseased\"]:\n",
    "                (output_dir / split / class_name).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Process each class directory\n",
    "        dataset_path = Path(dataset_path)\n",
    "        class_dirs = [d for d in dataset_path.iterdir() if d.is_dir()]\n",
    "        \n",
    "        healthy_count = 0\n",
    "        diseased_count = 0\n",
    "        \n",
    "        for class_dir in class_dirs:\n",
    "            class_name = class_dir.name.lower()\n",
    "            \n",
    "            # Determine if healthy or diseased\n",
    "            if \"healthy\" in class_name:\n",
    "                target_class = \"healthy\"\n",
    "            else:\n",
    "                target_class = \"diseased\"\n",
    "            \n",
    "            # Get all images\n",
    "            image_files = list(class_dir.glob(\"*.jpg\")) + list(class_dir.glob(\"*.jpeg\")) + list(class_dir.glob(\"*.png\"))\n",
    "            \n",
    "            if len(image_files) > 0:\n",
    "                print(f\"   {class_dir.name}: {len(image_files)} images ‚Üí {target_class}\")\n",
    "                \n",
    "                # Split 80/20\n",
    "                split_idx = int(len(image_files) * 0.8)\n",
    "                train_files = image_files[:split_idx]\n",
    "                val_files = image_files[split_idx:]\n",
    "                \n",
    "                # Copy files\n",
    "                for i, img_file in enumerate(train_files):\n",
    "                    dest = train_dir / target_class / f\"{class_dir.name}_{i:04d}.jpg\"\n",
    "                    shutil.copy2(img_file, dest)\n",
    "                \n",
    "                for i, img_file in enumerate(val_files):\n",
    "                    dest = val_dir / target_class / f\"{class_dir.name}_{i:04d}.jpg\"\n",
    "                    shutil.copy2(img_file, dest)\n",
    "                \n",
    "                if target_class == \"healthy\":\n",
    "                    healthy_count += len(image_files)\n",
    "                else:\n",
    "                    diseased_count += len(image_files)\n",
    "        \n",
    "        # Print summary\n",
    "        train_healthy = len(list((train_dir / \"healthy\").glob(\"*\")))\n",
    "        train_diseased = len(list((train_dir / \"diseased\").glob(\"*\")))\n",
    "        val_healthy = len(list((val_dir / \"healthy\").glob(\"*\")))\n",
    "        val_diseased = len(list((val_dir / \"diseased\").glob(\"*\")))\n",
    "        \n",
    "        print(f\"\\n‚úÖ Dataset reorganized!\")\n",
    "        print(f\"üìä Training: {train_healthy} healthy, {train_diseased} diseased\")\n",
    "        print(f\"üìä Validation: {val_healthy} healthy, {val_diseased} diseased\")\n",
    "        \n",
    "        return str(train_dir), str(val_dir)\n",
    "    \n",
    "    # Setup the dataset\n",
    "    TRAIN_DIR, VAL_DIR = setup_plantvillage_binary(dataset_folder)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dataset folder not found. Creating demo dataset...\")\n",
    "    # Option 2: For demo, create synthetic data\n",
    "    print(\"üîÑ Creating demo dataset...\")\n",
    "os.makedirs('demo_dataset/train/healthy', exist_ok=True)\n",
    "os.makedirs('demo_dataset/train/diseased', exist_ok=True)\n",
    "os.makedirs('demo_dataset/val/healthy', exist_ok=True)\n",
    "os.makedirs('demo_dataset/val/diseased', exist_ok=True)\n",
    "\n",
    "# Create some dummy images for demo\n",
    "for i in range(50):\n",
    "    # Healthy images (greenish)\n",
    "    img = np.random.randint(50, 200, (128, 128, 3), dtype=np.uint8)\n",
    "    img[:, :, 1] += 50  # More green\n",
    "    plt.imsave(f'demo_dataset/train/healthy/img_{i}.jpg', img)\n",
    "    \n",
    "    # Diseased images (brownish/yellowish)\n",
    "    img = np.random.randint(100, 255, (128, 128, 3), dtype=np.uint8)\n",
    "    img[:, :, 2] = img[:, :, 2] // 2  # Less blue\n",
    "    plt.imsave(f'demo_dataset/train/diseased/img_{i}.jpg', img)\n",
    "\n",
    "# Validation set\n",
    "for i in range(10):\n",
    "    img = np.random.randint(50, 200, (128, 128, 3), dtype=np.uint8)\n",
    "    img[:, :, 1] += 50\n",
    "    plt.imsave(f'demo_dataset/val/healthy/img_{i}.jpg', img)\n",
    "    \n",
    "    img = np.random.randint(100, 255, (128, 128, 3), dtype=np.uint8)\n",
    "    img[:, :, 2] = img[:, :, 2] // 2\n",
    "    plt.imsave(f'demo_dataset/val/diseased/img_{i}.jpg', img)\n",
    "\n",
    "print(\"‚úÖ Demo dataset created!\")\n",
    "\n",
    "# Set dataset paths (modify these for your actual dataset)\n",
    "TRAIN_DIR = 'demo_dataset/train'\n",
    "VAL_DIR = 'demo_dataset/val'\n",
    "\n",
    "print(f\"üìÅ Training data: {TRAIN_DIR}\")\n",
    "print(f\"üìÅ Validation data: {VAL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "def create_data_generators(train_dir, val_dir):\n",
    "    # Data augmentation for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Validation data (no augmentation)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=CONFIG['IMAGE_SIZE'],\n",
    "        batch_size=CONFIG['BATCH_SIZE'],\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=CONFIG['IMAGE_SIZE'],\n",
    "        batch_size=CONFIG['BATCH_SIZE'],\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator\n",
    "\n",
    "train_gen, val_gen = create_data_generators(TRAIN_DIR, VAL_DIR)\n",
    "\n",
    "print(f\"‚úÖ Training samples: {train_gen.samples}\")\n",
    "print(f\"‚úÖ Validation samples: {val_gen.samples}\")\n",
    "print(f\"‚úÖ Classes: {train_gen.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model architecture\n",
    "def create_mobile_model(num_classes=2, input_shape=(128, 128, 3)):\n",
    "    # Use MobileNetV2 as base (optimized for mobile)\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        alpha=0.75,  # Width multiplier for smaller model\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classification head\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_mobile_model(\n",
    "    num_classes=CONFIG['NUM_CLASSES'],\n",
    "    input_shape=(*CONFIG['IMAGE_SIZE'], 3)\n",
    ")\n",
    "\n",
    "print(\"üèóÔ∏è Model architecture created!\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=CONFIG['LEARNING_RATE']),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks for better training\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"üöÄ Starting training...\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=CONFIG['EPOCHS'],\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "final_acc = history.history['val_accuracy'][-1]\n",
    "print(f\"üéØ Final validation accuracy: {final_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow Lite with quantization\n",
    "def convert_to_tflite_optimized(model, model_name):\n",
    "    # Create representative dataset for quantization\n",
    "    def representative_dataset():\n",
    "        for _ in range(100):\n",
    "            # Use actual training data for better quantization\n",
    "            data = np.random.random((1, *CONFIG['IMAGE_SIZE'], 3)).astype(np.float32)\n",
    "            yield [data]\n",
    "    \n",
    "    # Convert with INT8 quantization (best for mobile)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_dataset\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    \n",
    "    try:\n",
    "        tflite_model = converter.convert()\n",
    "        print(\"‚úÖ INT8 quantized model created!\")\n",
    "        quantized = True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è INT8 quantization failed: {e}\")\n",
    "        print(\"Falling back to float32...\")\n",
    "        \n",
    "        # Fallback to float32\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        quantized = False\n",
    "        print(\"‚úÖ Float32 model created!\")\n",
    "    \n",
    "    # Save the model\n",
    "    filename = f'{model_name}_quantized.tflite' if quantized else f'{model_name}_float32.tflite'\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(f\"üíæ Model saved as: {filename}\")\n",
    "    print(f\"üìä Model size: {len(tflite_model)} bytes ({len(tflite_model)/1024:.1f} KB)\")\n",
    "    \n",
    "    return tflite_model, filename\n",
    "\n",
    "# Convert the model\n",
    "tflite_model, tflite_filename = convert_to_tflite_optimized(model, CONFIG['MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the TensorFlow Lite model\n",
    "def test_tflite_model(filename):\n",
    "    # Load the model\n",
    "    interpreter = tf.lite.Interpreter(model_path=filename)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    # Get input and output details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    print(\"üîç TensorFlow Lite Model Details:\")\n",
    "    print(f\"   Input shape: {input_details[0]['shape']}\")\n",
    "    print(f\"   Input type: {input_details[0]['dtype']}\")\n",
    "    print(f\"   Output shape: {output_details[0]['shape']}\")\n",
    "    print(f\"   Output type: {output_details[0]['dtype']}\")\n",
    "    \n",
    "    # Test with sample data\n",
    "    input_shape = input_details[0]['shape']\n",
    "    input_dtype = input_details[0]['dtype']\n",
    "    \n",
    "    if input_dtype == np.int8:\n",
    "        test_input = np.random.randint(-128, 127, input_shape, dtype=np.int8)\n",
    "    elif input_dtype == np.uint8:\n",
    "        test_input = np.random.randint(0, 255, input_shape, dtype=np.uint8)\n",
    "    else:\n",
    "        test_input = np.random.random(input_shape).astype(np.float32)\n",
    "    \n",
    "    # Run inference\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_input)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    print(f\"\\nüß™ Test Results:\")\n",
    "    print(f\"   Raw output: {output}\")\n",
    "    \n",
    "    # Convert output based on type\n",
    "    if output_details[0]['dtype'] == np.int8:\n",
    "        # Convert int8 to probabilities\n",
    "        probs = (output.astype(np.float32) + 128) / 255.0\n",
    "        print(f\"   Probabilities: {probs}\")\n",
    "        predicted_class = np.argmax(probs)\n",
    "    else:\n",
    "        predicted_class = np.argmax(output)\n",
    "    \n",
    "    class_names = ['healthy', 'diseased']\n",
    "    print(f\"   Predicted class: {predicted_class} ({class_names[predicted_class]})\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Test the model\n",
    "test_success = test_tflite_model(tflite_filename)\n",
    "print(\"\\n‚úÖ Model testing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels.txt file for Android\n",
    "labels = ['healthy', 'diseased']\n",
    "with open('labels.txt', 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write(f'{label}\\n')\n",
    "\n",
    "print(\"üìù labels.txt created!\")\n",
    "print(\"Labels:\", labels)\n",
    "\n",
    "# Display file sizes\n",
    "import os\n",
    "model_size = os.path.getsize(tflite_filename)\n",
    "labels_size = os.path.getsize('labels.txt')\n",
    "\n",
    "print(f\"\\nüìä Final Files:\")\n",
    "print(f\"   {tflite_filename}: {model_size} bytes ({model_size/1024:.1f} KB)\")\n",
    "print(f\"   labels.txt: {labels_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files for Android integration\n",
    "print(\"üì± Ready for Android Integration!\")\n",
    "print(\"\\nüîΩ Downloading files...\")\n",
    "\n",
    "# Download the model and labels\n",
    "files.download(tflite_filename)\n",
    "files.download('labels.txt')\n",
    "\n",
    "print(\"\\n‚úÖ Files downloaded!\")\n",
    "print(\"\\nüìã Next Steps:\")\n",
    "print(\"1. Replace 'app/src/main/assets/model.tflite' with the downloaded model\")\n",
    "print(\"2. Replace 'app/src/main/assets/labels.txt' with the downloaded labels\")\n",
    "print(\"3. Build and test your Android app\")\n",
    "print(\"4. The app should now work with real crop disease detection!\")\n",
    "\n",
    "print(\"\\nüéØ Model Specifications:\")\n",
    "print(f\"   Input: {CONFIG['IMAGE_SIZE'][0]}x{CONFIG['IMAGE_SIZE'][1]}x3\")\n",
    "print(f\"   Output: {CONFIG['NUM_CLASSES']} classes (healthy, diseased)\")\n",
    "print(f\"   Type: {'INT8 Quantized' if 'quantized' in tflite_filename else 'Float32'}\")\n",
    "print(f\"   Size: {model_size/1024:.1f} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}