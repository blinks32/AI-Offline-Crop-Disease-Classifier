{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå± Enhanced 3-Class Crop Disease Classifier\n",
    "\n",
    "This notebook creates a model with 3 classes:\n",
    "1. **Healthy** - Healthy crop leaves\n",
    "2. **Diseased** - Diseased crop leaves  \n",
    "3. **Not Crop** - Everything else (backgrounds, hands, objects, etc.)\n",
    "\n",
    "This solves the problem where the model classifies non-crop images as healthy/diseased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install tensorflow matplotlib pillow\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "print(\"‚úÖ TensorFlow version:\", tf.__version__)\n",
    "print(\"‚úÖ GPU available:\", len(tf.config.list_physical_devices('GPU')) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for 3-class model\n",
    "CONFIG = {\n",
    "    'IMAGE_SIZE': (128, 128),\n",
    "    'BATCH_SIZE': 32,\n",
    "    'EPOCHS': 20,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'NUM_CLASSES': 3,  # healthy, diseased, not_crop\n",
    "    'MODEL_NAME': 'enhanced_3class_crop_classifier'\n",
    "}\n",
    "\n",
    "print(\"üìã Enhanced Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload PlantVillage dataset\n",
    "print(\"üìÅ Upload your PlantVillage dataset:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract dataset\n",
    "zip_filename = list(uploaded.keys())[0]\n",
    "print(f\"üì¶ Extracting {zip_filename}...\")\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "\n",
    "print(\"‚úÖ Extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and setup PlantVillage dataset + create not_crop class\n",
    "def setup_3class_dataset():\n",
    "    from pathlib import Path\n",
    "    import shutil\n",
    "    import numpy as np\n",
    "    \n",
    "    # Find PlantVillage folder\n",
    "    dataset_folders = []\n",
    "    for item in Path('.').iterdir():\n",
    "        if item.is_dir():\n",
    "            subdirs = [d for d in item.iterdir() if d.is_dir()]\n",
    "            if len(subdirs) > 5:  # Likely a dataset\n",
    "                dataset_folders.append(item)\n",
    "    \n",
    "    if not dataset_folders:\n",
    "        print(\"‚ùå No dataset folder found!\")\n",
    "        return None, None\n",
    "    \n",
    "    source_folder = dataset_folders[0]\n",
    "    print(f\"üìÅ Using dataset: {source_folder.name}\")\n",
    "    \n",
    "    # Create 3-class structure\n",
    "    output_dir = Path(\"enhanced_crop_dataset\")\n",
    "    train_dir = output_dir / \"train\"\n",
    "    val_dir = output_dir / \"val\"\n",
    "    \n",
    "    # Remove existing\n",
    "    if output_dir.exists():\n",
    "        shutil.rmtree(output_dir)\n",
    "    \n",
    "    # Create 3-class structure\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        for class_name in [\"healthy\", \"diseased\", \"not_crop\"]:\n",
    "            (output_dir / split / class_name).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"üîÑ Processing PlantVillage classes...\")\n",
    "    \n",
    "    # Process PlantVillage classes\n",
    "    class_dirs = [d for d in source_folder.iterdir() if d.is_dir()]\n",
    "    \n",
    "    for class_dir in class_dirs:\n",
    "        class_name = class_dir.name.lower()\n",
    "        \n",
    "        # Determine target class\n",
    "        if \"healthy\" in class_name:\n",
    "            target_class = \"healthy\"\n",
    "        else:\n",
    "            target_class = \"diseased\"\n",
    "        \n",
    "        # Get images\n",
    "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.JPG', '.JPEG', '.PNG']\n",
    "        image_files = []\n",
    "        for ext in image_extensions:\n",
    "            image_files.extend(list(class_dir.glob(f\"*{ext}\")))\n",
    "        \n",
    "        if image_files:\n",
    "            print(f\"   üìÅ {class_dir.name}: {len(image_files)} images ‚Üí {target_class}\")\n",
    "            \n",
    "            # Shuffle and split\n",
    "            np.random.shuffle(image_files)\n",
    "            split_idx = int(len(image_files) * 0.8)\n",
    "            train_files = image_files[:split_idx]\n",
    "            val_files = image_files[split_idx:]\n",
    "            \n",
    "            # Copy files\n",
    "            for i, img_file in enumerate(train_files):\n",
    "                dest = train_dir / target_class / f\"{class_dir.name}_{i:04d}.jpg\"\n",
    "                shutil.copy2(img_file, dest)\n",
    "            \n",
    "            for i, img_file in enumerate(val_files):\n",
    "                dest = val_dir / target_class / f\"{class_dir.name}_{i:04d}.jpg\"\n",
    "                shutil.copy2(img_file, dest)\n",
    "    \n",
    "    print(\"\\nüîÑ Creating 'not_crop' class with synthetic data...\")\n",
    "    \n",
    "    # Create not_crop images (synthetic backgrounds, textures, etc.)\n",
    "    def create_not_crop_images(output_path, count):\n",
    "        for i in range(count):\n",
    "            # Create various non-crop images\n",
    "            img_type = i % 6\n",
    "            \n",
    "            if img_type == 0:\n",
    "                # Solid colors (walls, backgrounds)\n",
    "                color = np.random.randint(0, 255, 3)\n",
    "                img = np.full((128, 128, 3), color, dtype=np.uint8)\n",
    "            elif img_type == 1:\n",
    "                # Gradients\n",
    "                img = np.zeros((128, 128, 3), dtype=np.uint8)\n",
    "                for x in range(128):\n",
    "                    img[x, :, :] = x * 2\n",
    "            elif img_type == 2:\n",
    "                # Random noise (textured surfaces)\n",
    "                img = np.random.randint(0, 255, (128, 128, 3), dtype=np.uint8)\n",
    "            elif img_type == 3:\n",
    "                # Geometric patterns\n",
    "                img = np.zeros((128, 128, 3), dtype=np.uint8)\n",
    "                for x in range(0, 128, 10):\n",
    "                    img[x:x+5, :, :] = 255\n",
    "            elif img_type == 4:\n",
    "                # Checkerboard pattern\n",
    "                img = np.zeros((128, 128, 3), dtype=np.uint8)\n",
    "                for x in range(0, 128, 16):\n",
    "                    for y in range(0, 128, 16):\n",
    "                        if (x//16 + y//16) % 2 == 0:\n",
    "                            img[x:x+16, y:y+16, :] = 255\n",
    "            else:\n",
    "                # Circular patterns\n",
    "                img = np.zeros((128, 128, 3), dtype=np.uint8)\n",
    "                center = (64, 64)\n",
    "                radius = np.random.randint(20, 50)\n",
    "                y, x = np.ogrid[:128, :128]\n",
    "                mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2\n",
    "                img[mask] = np.random.randint(100, 255, 3)\n",
    "            \n",
    "            # Save image\n",
    "            img_pil = Image.fromarray(img)\n",
    "            img_pil.save(output_path / f\"not_crop_{i:04d}.jpg\")\n",
    "    \n",
    "    # Create not_crop training images\n",
    "    create_not_crop_images(train_dir / \"not_crop\", 2000)\n",
    "    create_not_crop_images(val_dir / \"not_crop\", 500)\n",
    "    \n",
    "    print(\"‚úÖ 3-class dataset created!\")\n",
    "    \n",
    "    # Verify counts\n",
    "    train_healthy = len(list((train_dir / \"healthy\").glob(\"*\")))\n",
    "    train_diseased = len(list((train_dir / \"diseased\").glob(\"*\")))\n",
    "    train_not_crop = len(list((train_dir / \"not_crop\").glob(\"*\")))\n",
    "    \n",
    "    val_healthy = len(list((val_dir / \"healthy\").glob(\"*\")))\n",
    "    val_diseased = len(list((val_dir / \"diseased\").glob(\"*\")))\n",
    "    val_not_crop = len(list((val_dir / \"not_crop\").glob(\"*\")))\n",
    "    \n",
    "    print(f\"\\nüìä Final Dataset:\")\n",
    "    print(f\"   Training: {train_healthy} healthy, {train_diseased} diseased, {train_not_crop} not_crop\")\n",
    "    print(f\"   Validation: {val_healthy} healthy, {val_diseased} diseased, {val_not_crop} not_crop\")\n",
    "    \n",
    "    return str(train_dir), str(val_dir)\n",
    "\n",
    "# Setup the enhanced dataset\n",
    "TRAIN_DIR, VAL_DIR = setup_3class_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators for 3-class training\n",
    "if TRAIN_DIR and VAL_DIR:\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=CONFIG['IMAGE_SIZE'],\n",
    "        batch_size=CONFIG['BATCH_SIZE'],\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        VAL_DIR,\n",
    "        target_size=CONFIG['IMAGE_SIZE'],\n",
    "        batch_size=CONFIG['BATCH_SIZE'],\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ 3-Class Data generators created!\")\n",
    "    print(f\"üìä Training samples: {train_generator.samples}\")\n",
    "    print(f\"üìä Validation samples: {val_generator.samples}\")\n",
    "    print(f\"üìä Classes: {train_generator.class_indices}\")\n",
    "    \n",
    "    # Show sample images from each class\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Get samples from each class\n",
    "    sample_batch, sample_labels = next(train_generator)\n",
    "    \n",
    "    class_names = ['diseased', 'healthy', 'not_crop']  # Based on alphabetical order\n",
    "    \n",
    "    for i in range(min(9, len(sample_batch))):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(sample_batch[i])\n",
    "        class_idx = np.argmax(sample_labels[i])\n",
    "        plt.title(f'{class_names[class_idx]}')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Images from 3 Classes')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Dataset setup failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3-class MobileNetV2 model\n",
    "def create_3class_model():\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=(*CONFIG['IMAGE_SIZE'], 3),\n",
    "        alpha=0.75,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(*CONFIG['IMAGE_SIZE'], 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)  # Higher dropout for 3 classes\n",
    "    outputs = Dense(CONFIG['NUM_CLASSES'], activation='softmax')(x)  # 3 classes\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_3class_model()\n",
    "\n",
    "print(\"üèóÔ∏è 3-Class Model created!\")\n",
    "print(f\"üìä Total parameters: {model.count_params():,}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the 3-class model\n",
    "if TRAIN_DIR and VAL_DIR:\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=CONFIG['LEARNING_RATE']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=7,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=4,\n",
    "            min_lr=1e-7\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(\"üöÄ Starting 3-class training...\")\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=CONFIG['EPOCHS'],\n",
    "        validation_data=val_generator,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ 3-class training completed!\")\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('3-Class Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('3-Class Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    final_acc = history.history['val_accuracy'][-1]\n",
    "    print(f\"üéØ Final validation accuracy: {final_acc:.3f} ({final_acc*100:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot train without dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TensorFlow Lite with INT8 quantization\n",
    "def convert_3class_to_tflite(model, model_name):\n",
    "    def representative_dataset():\n",
    "        for _ in range(100):\n",
    "            data = np.random.random((1, *CONFIG['IMAGE_SIZE'], 3)).astype(np.float32)\n",
    "            yield [data]\n",
    "    \n",
    "    print(\"üîÑ Converting 3-class model to TensorFlow Lite...\")\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_dataset\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    \n",
    "    try:\n",
    "        tflite_model = converter.convert()\n",
    "        filename = f'{model_name}_3class_int8.tflite'\n",
    "        print(\"‚úÖ INT8 3-class model created!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è INT8 conversion failed: {e}\")\n",
    "        print(\"üîÑ Falling back to float32...\")\n",
    "        \n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        filename = f'{model_name}_3class_float32.tflite'\n",
    "        print(\"‚úÖ Float32 3-class model created!\")\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(f\"üíæ Model saved as: {filename}\")\n",
    "    print(f\"üìä Model size: {len(tflite_model):,} bytes ({len(tflite_model)/1024:.1f} KB)\")\n",
    "    \n",
    "    return tflite_model, filename\n",
    "\n",
    "# Convert the model\n",
    "tflite_model, tflite_filename = convert_3class_to_tflite(model, CONFIG['MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the 3-class TensorFlow Lite model\n",
    "def test_3class_tflite_model(filename):\n",
    "    print(f\"üß™ Testing 3-class TensorFlow Lite model: {filename}\")\n",
    "    \n",
    "    interpreter = tf.lite.Interpreter(model_path=filename)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    print(\"\\nüîç Model Details:\")\n",
    "    print(f\"   Input shape: {input_details[0]['shape']}\")\n",
    "    print(f\"   Input type: {input_details[0]['dtype']}\")\n",
    "    print(f\"   Output shape: {output_details[0]['shape']}\")\n",
    "    print(f\"   Output type: {output_details[0]['dtype']}\")\n",
    "    \n",
    "    # Test with different types of input\n",
    "    input_shape = input_details[0]['shape']\n",
    "    input_dtype = input_details[0]['dtype']\n",
    "    \n",
    "    test_cases = [\n",
    "        (\"Random input\", np.random.random(input_shape).astype(np.float32)),\n",
    "        (\"Green image (crop-like)\", np.full(input_shape, [0.2, 0.8, 0.3], dtype=np.float32)),\n",
    "        (\"Gray image (background-like)\", np.full(input_shape, [0.5, 0.5, 0.5], dtype=np.float32))\n",
    "    ]\n",
    "    \n",
    "    class_names = ['diseased', 'healthy', 'not_crop']\n",
    "    \n",
    "    for test_name, test_input in test_cases:\n",
    "        # Convert to model input type\n",
    "        if input_dtype == np.int8:\n",
    "            model_input = ((test_input * 255) - 128).astype(np.int8)\n",
    "        elif input_dtype == np.uint8:\n",
    "            model_input = (test_input * 255).astype(np.uint8)\n",
    "        else:\n",
    "            model_input = test_input\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], model_input)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        # Convert output to probabilities\n",
    "        if output_details[0]['dtype'] == np.int8:\n",
    "            probs = (output.astype(np.float32) + 128) / 255.0\n",
    "        else:\n",
    "            probs = output\n",
    "        \n",
    "        predicted_class = np.argmax(probs)\n",
    "        confidence = np.max(probs)\n",
    "        \n",
    "        print(f\"\\nüß™ {test_name}:\")\n",
    "        print(f\"   Predicted: {class_names[predicted_class]} ({confidence:.3f} confidence)\")\n",
    "        print(f\"   All probabilities: {[f'{class_names[i]}: {probs[0][i]:.3f}' for i in range(3)]}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Test the model\n",
    "test_success = test_3class_tflite_model(tflite_filename)\n",
    "print(\"\\n‚úÖ 3-class model testing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3-class labels file\n",
    "labels_3class = ['diseased', 'healthy', 'not_crop']\n",
    "with open('labels_3class.txt', 'w') as f:\n",
    "    for label in labels_3class:\n",
    "        f.write(f'{label}\\n')\n",
    "\n",
    "print(\"üìù 3-class labels.txt created!\")\n",
    "print(f\"üìã Labels: {labels_3class}\")\n",
    "\n",
    "# Display final information\n",
    "model_size = os.path.getsize(tflite_filename)\n",
    "labels_size = os.path.getsize('labels_3class.txt')\n",
    "\n",
    "print(f\"\\nüìä Enhanced 3-Class Model Files:\")\n",
    "print(f\"   üì± {tflite_filename}: {model_size:,} bytes ({model_size/1024:.1f} KB)\")\n",
    "print(f\"   üìù labels_3class.txt: {labels_size} bytes\")\n",
    "\n",
    "print(f\"\\nüéØ Enhanced Model Specifications:\")\n",
    "print(f\"   üìê Input: {CONFIG['IMAGE_SIZE'][0]}x{CONFIG['IMAGE_SIZE'][1]}x3\")\n",
    "print(f\"   üè∑Ô∏è Classes: {CONFIG['NUM_CLASSES']} (diseased, healthy, not_crop)\")\n",
    "print(f\"   üî¢ Type: {'INT8 Quantized' if 'int8' in tflite_filename else 'Float32'}\")\n",
    "print(f\"   üíæ Size: {model_size/1024:.1f} KB\")\n",
    "\n",
    "print(f\"\\n‚ú® Key Improvement:\")\n",
    "print(f\"   üö´ Now detects when NOT pointing at crops!\")\n",
    "print(f\"   ‚úÖ Will show 'not_crop' for backgrounds, hands, walls, etc.\")\n",
    "print(f\"   üéØ More accurate crop disease detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the enhanced 3-class model\n",
    "print(\"üì± Enhanced 3-Class Model Ready!\")\n",
    "print(\"\\nüîΩ Downloading enhanced files...\")\n",
    "\n",
    "files.download(tflite_filename)\n",
    "files.download('labels_3class.txt')\n",
    "\n",
    "print(\"\\n‚úÖ Enhanced files downloaded!\")\n",
    "print(\"\\nüìã Android Integration Steps:\")\n",
    "print(\"1. üìÅ Replace 'app/src/main/assets/model.tflite' with the downloaded model\")\n",
    "print(\"2. üìù Replace 'app/src/main/assets/labels.txt' with 'labels_3class.txt'\")\n",
    "print(\"3. üî® Build your Android project: ./gradlew assembleDebug\")\n",
    "print(\"4. üì± Test the app - it will now detect non-crop objects!\")\n",
    "\n",
    "print(\"\\nüéâ Benefits of Enhanced Model:\")\n",
    "print(\"‚úÖ Detects when camera is NOT pointing at crops\")\n",
    "print(\"‚úÖ Shows 'not_crop' for backgrounds, hands, walls\")\n",
    "print(\"‚úÖ More accurate healthy/diseased classification\")\n",
    "print(\"‚úÖ Reduces false positives significantly\")\n",
    "print(\"‚úÖ Better user experience with realistic results\")\n",
    "\n",
    "print(\"\\nüí° Expected App Behavior:\")\n",
    "print(\"üå± Point at healthy crop ‚Üí 'Healthy: XX%'\")\n",
    "print(\"ü¶† Point at diseased crop ‚Üí 'Diseased: XX%'\")\n",
    "print(\"üö´ Point at wall/hand/background ‚Üí 'Not Crop: XX%'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "file_mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}